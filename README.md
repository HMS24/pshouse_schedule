# pshouse schedule
pre-sale house schedule

## æè¿°

é—œæ–¼**é å”®å±‹å¯¦åƒ¹ç™»éŒ„**çš„ EtLT å¯¦ä½œï¼Œå®šæœŸæ–¼æ¯æœˆ 1, 11, 21 æ—¥ä¸Šå…§æ”¿éƒ¨ç¶²ç«™ä¸‹è¼‰é å”®å±‹å¯¦åƒ¹ç™»éŒ„ï¼Œè‡ªå‹•åŒ–æª¢æŸ¥è³‡æ–™æ˜¯å¦å·²æ›´æ–°è‡³è³‡æ–™åº«ã€‚

é¦–å…ˆæ“·å–åˆ°è³‡æ–™å¾Œå…ˆä¸Šå‚³ AWS S3 å‚™ä»½ï¼Œå…¶æ¬¡åˆ©ç”¨ `pandas` package åšè³‡æ–™çš„å‰è™•ç†ï¼Œå†å­˜é€² ï¼­ySql è³‡æ–™åº«è½åœ°æ‡‰ç”¨ã€‚æœ€å¾Œå„²å­˜æ˜é¡¯æœ‰å•é¡Œçš„å¹¾ç­†å¯¦åƒ¹ç™»éŒ„ä¸¦ç”±äººå·¥æ ¡æ­£ã€‚é‹ä½œæ–¹å¼ä»¥ container çš„æ–¹å¼éƒ¨ç½²åˆ° AWS EC2 ä¸ŠåŸ·è¡Œã€‚å¦å¤–æµç¨‹çµæŸå¾Œç¢ºèªè³‡æ–™æ˜¯å¦æœ‰è¢«ä¸‹è¼‰åŠå­˜é€²è³‡æ–™åº«ï¼Œè‹¥ç„¡å‰‡ 1 å°æ™‚å€™å†åšä¸€æ¬¡ã€‚

**é™åˆ¶ 1: ç›®å‰åƒ…æŠ“æ–°åŒ—å¸‚çš„é å”®å±‹å¯¦åƒ¹ç™»éŒ„ï¼Œæ­·å²è³‡æ–™åŒ…å« 2021 ç¬¬ 2 å­£è‡³ 20220911(æœ¬æœŸæœ€æ–°)ã€‚**
    
## å¦‚ä½•ä½¿ç”¨

### å‰ç½®ä½œæ¥­

è¦éƒ¨ç½²åˆ°é ç«¯æ©Ÿå™¨ï¼Œå‡è¨­ç›®æ¨™æ©Ÿå™¨ OS ç‚º `Ubuntu 20.04`:
1. å®‰è£ `docker` and `docker compose`
2. æ–°å¢è³‡æ–™å¤¾ `mkdir ~/pshs` (`./deploy/publish.sh` æœ‰å¯«å…¥è³‡æ–™å¤¾çš„åç¨± )
3. è¨­ç½®ç’°å¢ƒè®Šæ•¸ `cd ~/pshs && vi .env`
4. ç’°å¢ƒè®Šæ•¸
    - `TOKEN`

### æœ¬åœ°éƒ¨ç½²
    
è¨­ç½®ç’°å¢ƒè®Šæ•¸

    $ cp .env.example .env

å»ºç«‹æ˜ åƒæª”ä¸¦éƒ¨ç½²ã€‚é è¨­æ˜ åƒæª”åç¨±åŠç‰ˆæœ¬: `local/pshs:latest`

    $ ./run.sh --target local

æŸ¥çœ‹ log

    $ docker logs -f pshs
    
    2022-09-01 00:50:17 [INFO] Adding job tentatively -- it will be properly scheduled when the scheduler starts
    2022-09-01 00:50:17 [INFO] Added job "crawl_deals" to job store "default"
    2022-09-01 00:50:17 [INFO] Scheduler started

### é ç«¯éƒ¨ç½²

å»ºç«‹æ˜ åƒæª”ä¸Šå‚³ docker hub ä¸¦éƒ¨ç½²ï¼Œé è¨­æ˜ åƒæª”åç¨±:`$DOCKER_USER/$IMAGE:$TAG`

    $ ./run.sh --target $REMOTE_MACHINE \
               --ssh-pem $REMOTE_MACHINE_PEM_PATH \
               --docker-user $DOCKER_USER \
               --docker-pass $DOCKER_PASSWORD_PATH \
               --image $IMAGE \
               --tag $TAG \
               --init $INIT_DATABASE

Parameters
- `REMOTE_MACHINE`: é ç«¯æ©Ÿå™¨ (user@hostname)
- `REMOTE_MACHINE_PEM_PATH`: pem æª”æ¡ˆä½ç½® ("$HOME/***.pem")
- `DOCKER_USER`: docker ä½¿ç”¨è€…
- `DOCKER_PASSWORD_PATH` docker å¯†ç¢¼æª”æ¡ˆä½ç½® ("$HOME/***")
- `IMAGE`(optional): æ˜ åƒæª”åç¨±
- `TAG`(optional) æ˜ åƒæª” tag
- `INIT_DATABASE`(optional) é‡ç½® database (0|1) 1 æœƒ truncate tableï¼Œå†æ’å…¥æ­·å²è³‡æ–™ã€‚é è¨­ 0

## æ¶æ§‹

```shell
.
â”œâ”€â”€ build
â”‚   â”œâ”€â”€ build.sh
â”‚   â”œâ”€â”€ test.sh                 # run container to test
â”‚   â”œâ”€â”€ push.sh
â”‚   â”œâ”€â”€ Dockerfile
â”œâ”€â”€ deploy               
â”‚   â”œâ”€â”€ deploy.sh           
â”‚   â”œâ”€â”€ publish.sh              # é ç«¯å•Ÿå‹•çš„ script
â”œâ”€â”€ pshouse_schedule
â”‚   â”œâ”€â”€ db
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ stores.py
â”‚   â”œâ”€â”€ jobs.py                 # å®šç¾© scheule çš„ job åŠ event handlers
â”‚   â”œâ”€â”€ processes.py            # æµç¨‹è™•ç†çš„ functions
â”‚   â”œâ”€â”€ fetch.py           
â”‚   â”œâ”€â”€ parse.py
â”‚   â”œâ”€â”€ load.py
â”‚   â”œâ”€â”€ storage.py
â”‚   â”œâ”€â”€ schemas.py             # validate åŠ type conversion
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ exceptions.py
â”œâ”€â”€ tests                       # æ¸¬è©¦                 
â”œâ”€â”€ results                     # å­˜æŠ“ä¸‹ä¾†çš„ csv æª”
â”œâ”€â”€ .env                    
â”œâ”€â”€ app.py                      # ç¨‹å¼å…¥å£
â”œâ”€â”€ boot.sh                     # run container çš„ entrypoint script
â”œâ”€â”€ compose.yml
â””â”€â”€ run.sh                      # åŸ·è¡Œ build and deploy çš„ script
```

### modules èªªæ˜ï¼š

- `boot.sh`: container entrypoint scriptã€‚æœªä¾†å¦‚è¦ç¢ºä¿ container çš„å•Ÿå‹•é †åºï¼Œæœƒå¢åŠ åƒæ˜¯ wait for db çš„ scriptï¼Œè€Œä¸ç”¨å†é‡æ–° build imageã€‚
- `app.py`: start schedule and keeps the main thread alived
- `jobs.py`: å®šç¾© job åŸ·è¡Œçš„æ–¹å¼(cron or interval) åŠèª¿ç”¨çš„ processã€‚å¦å¤–åŒ…å« `APScheduler` é è¨­çš„äº‹ä»¶è™•ç† functions
- `processes.py`: ä¸»è¦çš„æµç¨‹è™•ç†ã€‚
- `fetch.py`: æ“·å–è³‡æ–™çš„ functionsã€‚
- `parse.py`: è³‡æ–™æ“·å–å¾Œçš„è™•ç†ï¼Œè½‰æ›ä¸­è‹±æ¬„ä½ã€ç§»é™¤è‹±æ–‡æ¨™é¡Œåˆ—ã€è½‰æ›è‡³è¥¿å…ƒæ—¥æœŸã€å¡«è£œå„æ¬„ç©ºå€¼åŠæ–°å¢ `city` æ¬„ä½ã€‚
- `load.py`: å­˜é€² MySql è³‡æ–™åº«ï¼Œæœƒ import db è³‡æ–™å¤¾è£¡çš„ store ä¾†æ“ä½œ dbã€‚
- `storage.py`: ç”¨ `cloudstorage` å¯¦ä½œçš„ storage ä»‹é¢ï¼Œå¯ä»¥æ ¹æ“š `.env` çš„ `STORAGE_TYPE` é¸æ“‡ä¸Šå‚³æœ¬åœ°æˆ–é›²ç«¯(S3)
- `schemas.py`: å­˜å…¥ database å‰å°‡æ¬„ä½è³‡æ–™è½‰å‹ä¸¦åšåŸºæœ¬çš„ validateã€‚
- `db`
    - `database.py`: æœ‰å¯¦ä½œ session çš„ context managerï¼Œçµ±ä¸€ç®¡ç† session çš„ rollback åŠ closeã€‚
    - `models.py`:  database table çš„æŠ½è±¡å±¤ã€‚
    - `stores.py`: æ“ä½œ database çš„é‚è¼¯å±¤ã€‚å› ç‚ºéœ€æ±‚ç°¡å–®ï¼Œæ‰€ä»¥ç›´æ¥åœ¨é€™å€‹ module æ“ä½œ model è€Œéç”¨ __init__ çš„æ–¹å¼å‚³é€²å»ã€‚
- `build`
    - `build.sh`: æŒ‡å®šç‰¹å®š platform (linux/amd64)ï¼Œèˆ‡è¦éƒ¨ç½²çš„é ç«¯æ©Ÿå™¨ OS ä¸€è‡´ã€‚
    - `test.sh`:  run container ä¸¦ä¸”å®‰è£ pytest è·‘æ¸¬è©¦
    - `push.sh`: ç™»å…¥ docker æ¨è‡³ hub
- `deploy`
    - `deploy.sh`: compose.yml, .auth åŠ publish.sh å‚³è‡³é ç«¯æ©Ÿå™¨æº–å‚™éƒ¨ç½²
    - `publish.sh`: éƒ¨ç½² script

### æµç¨‹åœ–

<p align="center">
<img src="./assets/all.jpg" alt="all" width="1680"/>
</p>

### æµç¨‹èªªæ˜

- scheduler æ–°å¢ crawl cronjob
- æ¯æœˆ 1, 11, 21 æ—©ä¸Š 10:00 è§¸ç™¼è©² jobï¼Œä»¥ 9/21 ç‚ºä¾‹
- æŸ¥çœ‹å…§æ”¿éƒ¨**ä¸ŠæœŸ**çš„è³‡æ–™æœ‰ç„¡æ›´æ–°è‡³ 9/11
    - æœ‰
        - é–‹å§‹ fetch
        - å°‡ fetched çš„å…§å®¹ä¸Šå‚³è‡³ S3 å‚™ä»½
        - parse data:
            - æ²’å•é¡Œçš„ records å‰‡æ’å…¥ database
            - æœ‰å•é¡Œçš„å‰‡è½‰æ›è‡³ä¸­æ–‡æ¬„ä½(äººå·¥æ ¡å°æ¯”è¼ƒæ–¹ä¾¿)ï¼Œå­˜æˆ json ä¸Šå‚³ S3
    - æ²’æœ‰ return
- `APScheduler` ç™¼é€ JOB EXECUTED äº‹ä»¶
- ç›£è½å™¨åˆ¤æ–·æ˜¯å¦ç‚º crawl cronjob
    - æ˜¯ å‘¼å« handler
        - scheduler æ–°å¢ check crawl çš„ cronjob
    - å¦ exit
- ç«‹å³è§¸ç™¼ check crawl cronjob
    - åˆ¤æ–·å‰›æŠ“åˆ°çš„æª”æ¡ˆæ—¥æœŸæ˜¯å¦ç‚º 9/21
        - æ˜¯å‰‡ continue
        - å¦å‰‡ raise exception
    - åˆ¤æ–·æ’å…¥ database çš„æœ€å¾Œä¸€ç­† created_at æ˜¯å¦ç‚ºç•¶æ—¥(ä»£è¡¨è³‡æ–™å­˜é€² db)
        - æ˜¯å‰‡ continue
        - å¦å‰‡ raise exception
- è‹¥ä¸Šä¸€æ­¥æ²’æœ‰ raise some exceptionï¼Œå‰‡ 9/21 çš„è³‡æ–™å·²æŠ“åˆ°
- è‹¥æœ‰ raise exceptionï¼Œ`APScheduler` ç™¼é€ JOB ERROR äº‹ä»¶
- ç›£è½å™¨åˆ¤æ–·æ˜¯å¦ç‚º check crawl çš„ cronjobï¼Œä»¥åŠä¸Šè¿°çš„ exception type
    - æ˜¯å‰‡å‘¼å« handler
        - scheduler æ–°å¢ 1 å°æ™‚ä¹‹å¾Œçš„ crawl cronjob
    - å¦ exit

<!-- - Scheduler:

<p align="center">
<img src="./assets/scheduler.jpeg" alt="scheduler" width="300"/>
</p>

- Crawl process:

<p align="center">
<img src="./assets/crawl_job.jpeg" alt="crawl" width="300"/>
</p>

- Check process:

<p align="center">
<img src="./assets/check_job.jpeg" alt="check" width="300"/>
</p>

- Job executed listener

<p align="center">
<img src="./assets/job_executed_listener.jpeg" alt="executed_listener" width="300"/>
</p>

- Job error listener

<p align="center">
<img src="./assets/job_error_listener.jpeg" alt="error_listener" width="300"/>
</p> -->

## æœªä¾†æƒ³è¦

- æ–°å¢çµ±è¨ˆè¡¨ã€‚
    æ‰¾å‡ºæ–°åŒ—å¸‚æ·¡æ°´å€ä¸€å¹´å…§æ–°é–‹çš„é å”®æ¡ˆï¼Œçµ±è¨ˆå„æ¡ˆ 1ã€3 åŠ 6 å€‹æœˆå…¶ 10 åªä»¥ä¸‹ã€20 åªã€30 åªåŠ 40 åªä»¥ä¸Šçš„å¹³å‡å–®åƒ¹åŠç¸½åƒ¹ã€‚
    é€™ä¸€æ®µæƒ³å¯« raw SQL statement åŸ·è¡Œï¼Œç›´æ¥ transform dataã€‚
    æœªä¾†ç•¶å…¶ä»–ç¸£å¸‚è³‡æ–™ä¹ŸåŠ é€²ä¾†æ™‚å› ç‚ºè³‡æ–™å¾ˆå¤šï¼Œå¯ä»¥è€ƒæ…®ç›´æ¥å¾ S3 copy é€² Redshift(data warehouse)ï¼Œé‚£æ™‚å€™å–®ç´” sql æŸ¥è©¢çš„æ•ˆç‡æœƒæ¯”è¼ƒé«˜ã€‚è€Œä¸”è‹¥å¯«åœ¨ python é€™é‚Šè™•ç†ï¼Œå¯èƒ½è³‡æ–™é‡å¤ªå¤§ï¼Œè¨˜æ†¶é«” load ä¸é€²ä¾†(è‡ªå·±çŒœæ¸¬)
    
    1. æ¥åœ¨ check process ä¹‹å¾Œï¼Œç•¶ç¢ºèªæ²’å•é¡Œå‰‡é–‹å§‹é€™ä¸€æ®µ transform process
    2. models æ–°å¢ deal_statistics table
    3. ```sql
            INSERT INTO deal_statistics
            SELECT * FROM deals
            WHERE ...
            GROUP BY ...
        ```
    4. æ–°å¢ check deal_statistics process(æ˜¯å¦æœ‰å¿…è¦ï¼Ÿ)

- ä¸æ­£ç¢ºçš„ç´€éŒ„ï¼Œç¶“äººå·¥æ ¡æ­£å† insert into databaseã€‚
- å®šæœŸ mysql dumpï¼Œç›®å‰å¯ä»¥ç›´æ¥æŠ¹æ‰æ•´å¼µ tableï¼Œä½†æœªä¾†å¦‚æœ web application å¯ä»¥é–‹æ”¾ api å¾å‰ç«¯ update ä¸æ­£ç¢ºçš„è³‡è¨Šï¼Œå°±éœ€è¦å®šæœŸå‚™ä»½ã€‚

## é›œè¨˜

### é—œæ–¼ Database

åŸæœ¬æ˜¯èˆ‡ pshouse project ä¸€èµ·é–‹ç™¼ï¼Œå¾Œä¾†è¦ºå¾— code å¤ªé›œæ‹†åˆ† 2 å€‹å°ˆæ¡ˆåˆ†åˆ¥é–‹ç™¼ã€‚ schedule é—œæ³¨æ’ç¨‹æ˜¯å¦æœ‰è¢«æ­£ç¢ºçš„åŸ·è¡Œï¼Œä»¥åŠè³‡æ–™æ˜¯å¦å®Œæ•´çš„å­˜å…¥è³‡æ–™åº«ã€‚

è€Œ pshouse æ˜¯ç”± flask æ¡†æ¶é–‹ç™¼çš„ web applicationï¼Œé—œæ³¨çš„æ˜¯æœ€çµ‚ä½¿ç”¨è€…çš„éœ€æ±‚ã€‚å‘ˆç¾å–®é å¯¦åƒ¹ç™»éŒ„ä»¥å®¢è£½åŒ–æˆ‘è‡ªå·±çš„éœ€æ±‚ğŸ˜ƒã€‚
å¦å¤–é‚„èƒ½å¿«é€Ÿæœå°‹é—œéµå­—åŠæ’åºã€‚

å› æ­¤ï¼Œç›®å‰å…©é‚Šçš„ database æ˜¯å…±ç”¨çš„ã€‚ä¸¦ç”± web é‚£é‚Šåš migrateã€‚ç¼ºé»å°±æ˜¯å¿…é ˆç¶­è­·å…©é‚Šçš„ model å±¤ã€‚schedule åƒ…å»æ“·å–ä¸¦æ’å…¥è³‡æ–™è€Œå·²ã€‚
å¦å¤–å¦‚æœé€™é‚Šä¹Ÿç”¨ä¸€å€‹ database å­˜è³‡æ–™ï¼Œå†ç”± web é‚£é‚Šæ‰“ API é€²ä¾†æ‹¿...æœƒå¤§å¹…å¢åŠ é–‹ç™¼æˆæœ¬ã€‚

æœ€å¾Œ database çš„å»ºç½®æ˜¯ä»¥ container çš„æ–¹å¼å•Ÿå‹•ï¼Œä¸¦å¯«åœ¨ web çš„ `compose.yml` è£¡ï¼Œç„¶å¾Œ mount volume(db_data) åœ¨ host ä¸Šï¼Œæœƒé€ æˆä¸€äº›ä¸ä¾¿ã€‚å› ç‚ºæˆ‘å°‡ app è·Ÿ db æ”¾åœ¨åŒä¸€å€‹ container bridge çš„ networks ä¹‹ä¸­ï¼Œç•¶è¦éƒ¨ç½² schedule æ™‚å¾—ç¢ºä¿ web é‚£é‚Šçš„ database å…ˆ run èµ·ä¾†ï¼Œè€Œ schedule é€™é‚Šæ‰èƒ½å» link db...æœ‰é»ç¹ã€‚

è§£æ±ºæ–¹å¼æ˜¯æŠŠ database æœå‹™æ‹†å‡ºä¾†ï¼Œæœ€ç°¡å–®å°±æ˜¯ä½¿ç”¨ AWS rds çš„æœå‹™ã€‚

### é—œæ–¼ Schedule

schedule æ–¹é¢

1. Crontab
2. APscheduler
3. Airflow
4. AWS Lambda è¨­å®š event åŠ rate

`1` ç›®å‰éœ€æ±‚ç‚ºä¸€å€‹ cronjobï¼Œä¸éé€™å€‹å°ˆæ¡ˆä¹‹å¾Œæƒ³åšçš„æ’ç¨‹ cronjob ä¸ç®—å°‘ï¼Œå› æ­¤ç®¡ç†ä¸Šä¸æ–¹ä¾¿ã€‚

`2` åƒ…ç”¨ python å°±èƒ½è§£æ±ºï¼Œç›¸å° `1` ç¬¦åˆæœªä¾† cronjob çš„æ“´å……ï¼Œä½†ç›®å‰ç‰ˆæœ¬åƒ…æœ‰ default çš„ eventï¼Œä¸”ç„¡æ³•æ§åˆ¶ä½•æ™‚ emit event åŠ custom event typeï¼Œå¾—æ‰¾å…¶ä»– package è¼”åŠ©ï¼Œé¡¯ç„¶æœ‰é»ç¾ä¸­ä¸è¶³ã€‚

`3` æ¶è¨­ airflow server ä»¥ configuration as code å»ºé€  ETLã€‚çœ‹äº†ä¸€ä¸‹æœ‰è »å¤šåŠŸèƒ½ï¼Œå¯ä»¥ task é‡è·‘ä¹Ÿå¯ä»¥å°‡ task çµ„åˆæˆä¸ä¸€æ¨£çš„ ETL æµç¨‹ï¼Œæ„Ÿè¦ºæ˜¯é …åˆ©å™¨ã€‚

`4` ä»¥ cloud çš„æ–¹å¼ç›¸å°ä¸ç†Ÿã€‚

å…ˆé¸ `2` çš„æ–¹å¼é–‹ç™¼ã€‚

### é—œæ–¼æ¸¬è©¦